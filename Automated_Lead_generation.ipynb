{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "start=time.time()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.warning('ICV FILE LOG---------time of compilation--------'+str(dt.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C://Users//tjoseph//Desktop//ICV docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('PO List 2014 to 2016.xlsx')\n",
    "df_agency=pd.read_excel('Copy of Div BusUnit PM.xlsx')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['COUNTRY','CURRENCY_CODE','RATE','QUANTITY','TOTAL'],inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uts_principals=df_agency['AGENCYNAME'].tolist()\n",
    "from collections import Counter\n",
    "dictionary=dict(Counter([x for x in uts_principals]))\n",
    "uts_principals=list(dictionary.keys())\n",
    "uts_principals.append('SUMITOMO')\n",
    "uts_principals.append('HPILLC')\n",
    "uts_principals.append('HPI LLC')\n",
    "uts_principals.append('HPI ENERGY SERVICES LLC')\n",
    "uts_principals.append('CLAYTON OF BELGIUM N.V')\n",
    "uts_principals.append('UTS CARRIER LLC')\n",
    "uts_principals.append('PCS ITALIANA s.r.l')\n",
    "uts_principals.append('NIKKISO CRYO INC')\n",
    "uts_principals.append('JCC-NIKKISO')\n",
    "uts_principals.append('HOOVER CONTAINER SOLUTIONS FOR MECHANICAL EQUIPMENT LLC')\n",
    "uts_principals.append('Evac Germany GmbH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_bu_division(category,business_unit,division,product_manager):\n",
    "    df.loc[(df['CATEGORY']==str(category)),'BUSINESS UNIT']=str(business_unit)\n",
    "    df.loc[(df['BUSINESS UNIT']==str(business_unit)),'DIVISION']=str(division)\n",
    "    \n",
    "    df.loc[(df['BUSINESS UNIT']==str(business_unit)),'PRODUCT MANAGER']=str(product_manager) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_bu_division('EVAC.Parts','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('EVAC.Equipment','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('MG & G PUMP.Parts','Water','Energy','Shajimon Ragam')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorize_bu_division('EVAC.Others','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('METOS.Parts','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('HATENBOER.Parts','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('HATENBOER.Equipment','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('DETEGASA.Equipment','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('METOS.Equipment','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('PCS ITALIANA.Parts','Marine','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('DETEGASA.Parts','Marine','Energy','Shajimon Ragam')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorize_bu_division('MECO.Chemicals','Water','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('MECO.Parts','Water','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('MECO.Others','Water','Energy','Shajimon Ragam')\n",
    "categorize_bu_division('MECO.Equipment','Water','Energy','Shajimon Ragam')\n",
    "\n",
    "\n",
    "\n",
    "categorize_bu_division('ALFA LAVAL.Parts','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('ALFA LAVAL.Equipment','Process Control','Energy','Shahid Jamil')\n",
    "\n",
    "categorize_bu_division('YOKOGAWA.Equipment','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('YOKOGAWA.Parts','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('CLAYTON.Parts','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('HPI.Equipment','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('CLAYTON.Equipment','Process Control','Energy','Shahid Jamil')\n",
    "categorize_bu_division('JC CARTER CO INC.Parts','Process Control','Energy','Shahid Jamil')\n",
    "\n",
    "\n",
    "categorize_bu_division('BAKER HUGHES.Drilling Bits','Rockbits','Drilling','H N Shetty')\n",
    "categorize_bu_division('CENTERGENICS','Drilling','Drilling','H N Shetty')\n",
    "\n",
    "categorize_bu_division('SUMITOMO.Tubing','Linepipes','Drilling','H N Shetty')\n",
    "categorize_bu_division('SUMITOMO.Accessory','Linepipes','Drilling','H N Shetty')\n",
    "categorize_bu_division('SUMITOMO.Casing','Linepipes','Drilling','H N Shetty')\n",
    "categorize_bu_division('SUMITOMO.Xover','Linepipes','Drilling','H N Shetty')\n",
    "categorize_bu_division('SUMITOMO.Pipes','Linepipes','Drilling','H N Shetty')\n",
    "\n",
    "\n",
    "\n",
    "categorize_bu_division('HEALTHCARE.Equipment','Healthcare','Healthcare','Munir Malak')\n",
    "categorize_bu_division('HEALTHCARE.Parts','Healthcare','Healthcare','Munir Malak')\n",
    "categorize_bu_division('TEDESCHI.Furniture','Furniture','Furniture','Jihad Hazzan')\n",
    " \n",
    "    \n",
    "categorize_bu_division('PRODUCTION CHEMICALS.Chemicals','Chemical','Chemical','Khaled Jamal Soubeh')\n",
    "categorize_bu_division('CHEMTREAT.Chemicals','Chemical','Chemical','Khaled Jamal Soubeh')\n",
    "categorize_bu_division('DRILLING CHEMICALS.Chemicals','Chemical','Chemical','Khaled Jamal Soubeh')\n",
    "categorize_bu_division('CHEMTREAT.Equipment','Chemical','Chemical','Khaled Jamal Soubeh')\n",
    "categorize_bu_division('PRODUCTION CHEMICALS.Equipment','Chemical','Chemical','Khaled Jamal Soubeh')\n",
    "\n",
    "categorize_bu_division('PIPES GEN.Parts','Linepipes','Linepipes','Rashid Ishaq')\n",
    "categorize_bu_division('PIPES GEN.Equipment','Linepipes','Linepipes','Rashid Ishaq')\n",
    "categorize_bu_division('PIPES GEN.Others','Linepipes','Linepipes','Rashid Ishaq')\n",
    "\n",
    "#categorize_bu_division('MISCELLANEOUS.Others','Misc','Misc','Misc')\n",
    "\n",
    "categorize_bu_division('ENR OTH RFT.Parts','Others (E)','Energy','Rafaat Assaf Mallat')\n",
    "categorize_bu_division('ENR OTH RFT.Equipment','Others (E)','Energy','Rafaat Assaf Mallat')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorizing principle using CATEGORY\n",
    "\n",
    "def categorize_pricipal(category,agency):\n",
    "    df.loc[(df['CATEGORY']==str(category)),'Agency_by_cat']=str(agency)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorizing principle using CATEGORY\n",
    "\n",
    "categorize_pricipal('EVAC.Parts','EVAC')\n",
    "categorize_pricipal('EVAC.Others','EVAC')\n",
    "categorize_pricipal('EVAC.Equipment','EVAC')\n",
    "\n",
    "\n",
    "categorize_pricipal('MECO.Parts','MECO')\n",
    "categorize_pricipal('ALFA LAVAL.Parts','ALFA LAVAL')\n",
    "categorize_pricipal('YOKOGAWA.Equipment','YOKOGAWA')\n",
    "categorize_pricipal('BAKER HUGHES.Drilling Bits','BAKER HUGHES')\n",
    "categorize_pricipal('HEALTHCARE.Parts','HEALTHCARE')\n",
    "categorize_pricipal('HATENBOER.Parts','HATENBOER')\n",
    "categorize_pricipal('ALFA LAVAL.Equipment','ALFA LAVAL')\n",
    "\n",
    "categorize_pricipal('PRODUCTION CHEMICALS.Chemicals','PROD CHEM')\n",
    "categorize_pricipal('PRODUCTION CHEMICALS.Equipment','PROD CHEM')\n",
    "\n",
    "categorize_pricipal('METOS.Equipment','METOS')\n",
    "categorize_pricipal('METOS.Parts','METOS')\n",
    "\n",
    "\n",
    "categorize_pricipal('MECO.Chemicals','MECO')\n",
    "\n",
    "categorize_pricipal('PIPES GEN.Parts','TECH SUPPLIES')\n",
    "categorize_pricipal('PIPES GEN.Equipment','TECH SUPPLIES')\n",
    "categorize_pricipal('PIPES GEN.Others','TECH SUPPLIES')\n",
    "\n",
    "\n",
    "categorize_pricipal('CHEMTREAT.Chemicals','CHEMTREAT')\n",
    "\n",
    "categorize_pricipal('SUMITOMO.Tubing','SUMITOMO')\n",
    "categorize_pricipal('SUMITOMO.Accessory','SUMITOMO')\n",
    "\n",
    "\n",
    "categorize_pricipal('DRILLING CHEMICALS.Chemicals','DRILL CHEM')\n",
    "\n",
    "categorize_pricipal('HATENBOER.Equipment','HATENBOER')\n",
    "categorize_pricipal('SUMITOMO.Casing','SUMITOMO')\n",
    "\n",
    "categorize_pricipal('HEALTHCARE','HEALTHCARE')\n",
    "categorize_pricipal('DETEGASA.Equipment','DETEGASA')\n",
    "\n",
    "categorize_pricipal('CHEMTREAT.Equipment','CHEMTREAT')\n",
    "\n",
    "categorize_pricipal('MECO.Others','MECO')\n",
    "\n",
    "categorize_pricipal('MECO.Equipment','MECO')\n",
    "categorize_pricipal('CLAYTON.Parts','CLAYTON')\n",
    "\n",
    "categorize_pricipal('HPI.Equipment','HPI')\n",
    "categorize_pricipal('PCS ITALIANA.Parts','PCS ITALIANA')\n",
    "\n",
    "categorize_pricipal('CENTERGENICS.Equipment','CENTERGENICS')\n",
    "categorize_pricipal('CLAYTON.Equipment','CLAYTON')\n",
    "categorize_pricipal('DETEGASA.Parts','DETEGASA')\n",
    "\n",
    "#NOT REAL CATEGORY\n",
    "\n",
    "categorize_pricipal('MISCELLANEOUS.Others','MISCELLANEOUS')\n",
    "categorize_pricipal('ESOLVE.Parts','ESOLVE')\n",
    "categorize_pricipal('MISCELLANEOUS.Equipment','MISCELLANEOUS')\n",
    "categorize_pricipal('M004.ZERO','MISCELLANEOUS')\n",
    "categorize_pricipal('JC CARTER CO INC.Parts','JC CARTER CO INC.Parts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agency_by_vendor(vendor,agency_by_vendor):\n",
    "    df.loc[(df['VENDOR_NAME']==str(vendor),'Agency_by_vendor')]=str(agency_by_vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_by_vendor('EVAC OY','EVAC')\n",
    "agency_by_vendor('EVAC NORTH AMERICA INC..','EVAC')\n",
    "\n",
    "\n",
    "agency_by_vendor('YOKOGAWA MIDDLE EAST & AFRICA B.S.C. (Bahrain)','YOKOGAWA')\n",
    "agency_by_vendor('YOKOGAWA MIDDLE EAST & AFRICA B.S.C. (Closed - Abu Dhabi)','YOKOGAWA')\n",
    "\n",
    "\n",
    "\n",
    "agency_by_vendor('ALFA LAVAL MIDDLE EAST','ALFA LAVAL')\n",
    "agency_by_vendor('MECHANICAL EQUIPMENT CO. INC.','MECO')\n",
    "agency_by_vendor('METOS OY','METOS')\n",
    "agency_by_vendor('BAKER HUGHES EHO LTD','BAKER HUGHES')\n",
    "agency_by_vendor('HATENBOER-WATER BV','HATENBOER')\n",
    "agency_by_vendor('SUMITOMO CORPORATION MIDDLE EAST FZE (SCME FZE)','SUMITOMO')\n",
    "agency_by_vendor('CENTERGENICS, LLC','CENTERGENICS')\n",
    "\n",
    "agency_by_vendor('CHEMTREAT INC','CHEMTREAT')\n",
    "agency_by_vendor('DETEGASA','DETEGASA')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Agency_by_vendor']=df.apply(lambda x:x['Agency_by_vendor'] if pd.notnull(x['Agency_by_vendor']) else x['VENDOR_NAME'],axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.apply(lambda x:x['Agency_by_vendor'] if pd.notnull(x['Agency_by_vendor']) else x['VENDOR_NAME'],axis=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Agency_by_vendor'].isin(uts_principals)==True),'Bought_from_principal']='Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bought_from_principal'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bought_from_principal'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bought_from_principal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx=df[['ITEM_DESCRIPTION','CATEGORY','Agency_by_cat','VENDOR_NAME','Agency_by_vendor','Bought_from_principal','TOTALINAED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Agency_by_cat'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIVISION'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIVISION'].fillna('No Division Found',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BUSINESS UNIT'].fillna('No BUSINESS UNIT Found',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['CATEGORY']=='MISCELLANEOUS.Others'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ATTRIBUTE9','ATTRIBUTE8','COMMENTS','UNIT_PRICE'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bought_from_others=df[df['Bought_from_principal']=='No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_bought_from_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of purhases made from abroad :{0}\".format(len(df_bought_from_others[~(df_bought_from_others['COUNTRYNAME']==\"UNITED ARAB EMIRATES\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase=df_bought_from_others[df_bought_from_others['COUNTRYNAME']!='UNITED ARAB EMIRATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NULL VALUES in DATAFRAME:',df_non_UAE_purchase['COUNTRYNAME'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase=df_non_UAE_purchase[['ITEM_DESCRIPTION','CATEGORY','VENDOR_NAME','COUNTRYNAME','Agency_by_vendor',\\\n",
    "                     'Agency_by_cat','PARTNUMBER', 'PODATE',\\\n",
    "                     'PONUMBER', 'TOTALINAED','BUSINESS UNIT',\\\n",
    "                       'DIVISION', 'PRODUCT MANAGER','Bought_from_principal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of dataframe:',len(df_non_UAE_purchase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase['COUNTRYNAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase.sort_values(by=['TOTALINAED'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Non_UAE_suppliers: ',df_non_UAE_purchase['VENDOR_NAME'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_supplier_list=df['VENDOR_NAME'].unique()\n",
    "unique_supplier_list=list(unique_supplier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "input_file=open('findel_education_list.pkl','rb')\n",
    "findel_education_list=pickle.load(input_file)\n",
    "input_file.close()\n",
    "input_file=open('sports_thieme_list.pkl','rb')\n",
    "sports_theieme_list=pickle.load(input_file)\n",
    "input_file.close()\n",
    "os.chdir('C:\\\\Users\\\\tjoseph\\\\Desktop\\\\ICV docs')\n",
    "kids_equipments=findel_education_list+sports_theieme_list\n",
    "\n",
    "def categorize_all(df):\n",
    "    \n",
    "    print('********************please wait while Categorizing**************************')\n",
    "\n",
    "    pub=df['ITEM_DESCRIPTION']\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    df_pm=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','pm_list')\n",
    "    df_chemical=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','chemical_keyword')\n",
    "    df['Category']=\"\"\n",
    "    def funnel_contains():\n",
    "        for pm_category in df_pm['Products']:\n",
    "            keyword=pub.str.contains(str(pm_category),case=False)\n",
    "            df['Category']=np.where(keyword,pm_category,df['Category'])\n",
    "    funnel_contains()\n",
    "    \n",
    "    #Funnel 4-Drill Bits \n",
    "    df_drill_bit=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','drill_bit')\n",
    "\n",
    "    def drill_bits():\n",
    "\n",
    "        for drill_bit in df_drill_bit['Drill Bit Keywords']:\n",
    "\n",
    "            drill_keyword=pub.str.contains(drill_bit,case=False)\n",
    "            df['Category']=np.where(drill_keyword,'Drill Bits',df['Category'])\n",
    "    drill_bits()  \n",
    "\n",
    "    df[df['Category']=='Drill Bits'].count()\n",
    "    df[df['Category']!=\"\"].count()\n",
    "\n",
    "    #Special Cases_Funnel 6\n",
    "\n",
    "    def special_cases():\n",
    "\n",
    "\n",
    "        transmitter=pub.str.contains('transmitter',case=False)       \n",
    "        df['Category']=np.where(transmitter,'Transmitter',df['Category'])\n",
    "\n",
    "        transmitter=pub.str.contains('transmit',case=False)       \n",
    "        df['Category']=np.where(transmitter,'Transmitter',df['Category'])\n",
    "\n",
    "        transmitter=pub.str.contains('PRESS TRANS',case=False)       \n",
    "        df['Category']=np.where(transmitter,'Transmitter',df['Category'])\n",
    "\n",
    "        transmitter=pub.str.contains('TEMP TRANS',case=False)       \n",
    "        df['Category']=np.where(transmitter,'Transmitter',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        differential=pub.str.contains('Differential',case=False)       \n",
    "        df['Category']=np.where(differential,'Differential Pressure',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        differential=pub.str.contains('Diff',case=False)       \n",
    "        df['Category']=np.where(differential,'Differential Pressure',df['Category'])\n",
    "\n",
    "        diff_null=pub.str.contains('Diffu',case=False)       \n",
    "        df['Category']=np.where(diff_null,\"\",df['Category'])\n",
    "        \n",
    "        impeller=pub.str.contains('impell',case=False)       \n",
    "        df['Category']=np.where(impeller,\"Impeller\",df['Category'])\n",
    "\n",
    "\n",
    "       # diff_null=pub.str.match('Different',case=False)       \n",
    "       # df['Category']=np.where(diff_null,\"\",df['Category'])\n",
    "\n",
    "\n",
    "        diff_null=pub.str.contains('Diffu',case=False)       \n",
    "        df['Category']=np.where(diff_null,\"\",df['Category'])\n",
    "\n",
    "        analyzer=pub.str.contains('Analy',case=False) \n",
    "        df['Category']=np.where(analyzer,'Analyzers',df['Category'])\n",
    "\n",
    "        analyzer=pub.str.contains('Analyser',case=False) \n",
    "        df['Category']=np.where(analyzer,'Analyzers',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        bend=pub.str.contains('bend',case=False)\n",
    "        df['Category']=np.where(bend,'3D/5D Bends',df['Category'])\n",
    "\n",
    "        battery=pub.str.contains('battery',case=False)\n",
    "        df['Category']=np.where(battery,'Batteries',df['Category'])\n",
    "\n",
    "        battr=pub.str.contains('battr',case=False)\n",
    "        df['Category']=np.where(battr,'Batteries',df['Category'])\n",
    "\n",
    "        blood_gas_analyzer=pub.str.contains('Blood gas analyzer',case=False)\n",
    "        df['Category']=np.where(blood_gas_analyzer,'Blood gas analyzer',df['Category'])\n",
    "\n",
    "        blood_gas_analyzer=pub.str.contains('Bloodgas analyzer',case=False)\n",
    "        df['Category']=np.where(blood_gas_analyzer,'Blood gas analyzer',df['Category'])\n",
    "\n",
    "        blood_gas_analyzer=pub.str.contains('Bloodgasanalyzer',case=False)\n",
    "        df['Category']=np.where(blood_gas_analyzer,'Blood gas analyzer',df['Category'])\n",
    "\n",
    "        bolt=pub.str.contains('bolt',case=False)\n",
    "        df['Category']=np.where(bolt,'Bolts',df['Category'])\n",
    "\n",
    "        heater=pub.str.contains('heater',case=False)\n",
    "        df['Category']=np.where(heater,'HVAC',df['Category'])\n",
    "\n",
    "        bulb=pub.str.contains('bulb',case=False)\n",
    "        df['Category']=np.where(bulb,'Bulbs/lamps',df['Category'])\n",
    "\n",
    "        lamp=pub.str.contains('lamp',case=False)\n",
    "        df['Category']=np.where(lamp,'Bulbs/lamps',df['Category'])\n",
    "\n",
    "        fitting=pub.str.contains('fitting',case=False)\n",
    "        df['Category']=np.where(fitting,'Fittings',df['Category'])\n",
    "\n",
    "        fitt=pub.str.contains('fitt',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('STRAINER',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('NPT',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('MALE BRASS',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('BRASS PORTS',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitting=pub.str.contains('plunge',case=False)\n",
    "        df['Category']=np.where(fitting,'Fittings',df['Category'])\n",
    "        \n",
    "        fitting=pub.str.contains('plug',case=False)\n",
    "        df['Category']=np.where(fitting,'Fittings',df['Category'])\n",
    "        \n",
    "        \n",
    "\n",
    " \n",
    "\n",
    "        pump=pub.str.contains('pump',case=False)\n",
    "        df['Category']=np.where(pump,'Pumps',df['Category']) #work on Pump  classification\n",
    "\n",
    "        topog=pub.str.contains('topog',case=False)\n",
    "        df['Category']=np.where(topog,'CMS,GIS Topography',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        GIS=pub.str.contains('GIS',case=False)\n",
    "        df['Category']=np.where(GIS,'CMS,GIS Topography',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        valves=pub.str.contains('valv',case=False)\n",
    "        df['Category']=np.where(valves,'Valves',df['Category']) #New Category added\n",
    "\n",
    "        controllers=pub.str.contains('controlle',case=False)\n",
    "        df['Category']=np.where(controllers,'Controllers and Indicators',df['Category'])\n",
    "\n",
    "        indicators=pub.str.contains('indicat',case=False)\n",
    "        df['Category']=np.where(indicators,'Controllers and Indicators',df['Category'])\n",
    "\n",
    "        flange=pub.str.contains('flang',case=False)\n",
    "        df['Category']=np.where(flange,'Flanges',df['Category'])\n",
    "\n",
    "        current_to_pneumatic=pub.str.contains('current to pneumatic',case=False)\n",
    "        df['Category']=np.where(current_to_pneumatic,'Current-to-Pneumatic',df['Category'])\n",
    "\n",
    "        current_to_pneumatic=pub.str.contains('currentto pneumatic',case=False)\n",
    "        df['Category']=np.where(current_to_pneumatic,'Current-to-Pneumatic',df['Category'])\n",
    "\n",
    "        current_to_pneumatic=pub.str.contains('current topneumatic',case=False)\n",
    "        df['Category']=np.where(current_to_pneumatic,'Current-to-Pneumatic',df['Category'])\n",
    "\n",
    "        current_to_pneumatic=pub.str.contains('current pneumatic',case=False)\n",
    "        df['Category']=np.where(current_to_pneumatic,'Current-to-Pneumatic',df['Category'])\n",
    "\n",
    "        current_to_pneumatic=pub.str.contains('currentpneumatic',case=False)\n",
    "        df['Category']=np.where(current_to_pneumatic,'Current-to-Pneumatic',df['Category'])\n",
    "\n",
    "        decanter=pub.str.contains('decan',case=False)\n",
    "        df['Category']=np.where(decanter,'Decanters',df['Category'])\n",
    "\n",
    "        dental=pub.str.contains('dental',case=False)\n",
    "        df['Category']=np.where(dental,'Dental eqpt',df['Category'])\n",
    "\n",
    "        electric_motor=pub.str.contains('electric motor',case=False)\n",
    "        df['Category']=np.where(electric_motor,'Electric Motor',df['Category'])\n",
    "\n",
    "        pipe=pub.str.contains('pipe',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "\n",
    "        pipe=pub.str.contains('piping',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "        \n",
    "        pipe=pub.str.contains('pvc',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "        \n",
    "        elbow=pub.str.contains('elbow',case=False)\n",
    "        df['Category']=np.where(elbow,'Elbows',df['Category'])\n",
    "        \n",
    "        socket=pub.str.contains('socket',case=False)\n",
    "        df['Category']=np.where(socket,'Socket',df['Category'])\n",
    "        \n",
    "      \n",
    "        fan=pub.str.contains('fan',case=False)\n",
    "        df['Category']=np.where(fan,'FCU',df['Category'])\n",
    "\n",
    "        furniture=pub.str.contains('furnit',case=False)\n",
    "        df['Category']=np.where(furniture,'Domestic Furniture & Fixtures',df['Category'])\n",
    "\n",
    "\n",
    "        furniture=pub.str.contains('walk',case=False)\n",
    "        df['Category']=np.where(furniture,'Domestic Furniture & Fixtures',df['Category'])\n",
    "\n",
    "        furniture=pub.str.contains('door',case=False)\n",
    "        df['Category']=np.where(furniture,'Domestic Furniture & Fixtures',df['Category'])\n",
    "\n",
    "\n",
    "        facilit_mgmt=pub.str.contains('facilities management',case=False)\n",
    "        df['Category']=np.where(facilit_mgmt,'Facility Management',df['Category'])\n",
    "\n",
    "        filtr=pub.str.contains('filt',case=False)\n",
    "        df['Category']=np.where(filtr,'Filters',df['Category'])\n",
    "\n",
    "        fire_fighting=pub.str.contains('fire',case=False)\n",
    "        df['Category']=np.where(fire_fighting,'Firefighting',df['Category'])\n",
    "\n",
    "        flame=pub.str.contains('flame',case=False)\n",
    "        df['Category']=np.where(flame,'Firefighting',df['Category'])\n",
    "\n",
    "\n",
    "        flow_meter=pub.str.contains('flow meter',case=False)\n",
    "        df['Category']=np.where(flow_meter,'Flow Meters',df['Category'])\n",
    "\n",
    "        flow_meter=pub.str.contains('flowmeter',case=False)\n",
    "        df['Category']=np.where(flow_meter,'Flow Meters',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        water_mkr=pub.str.contains('maker',case=False)\n",
    "        df['Category']=np.where(water_mkr,'Fresh Water Maker (RO / VC type)',df['Category']) \n",
    "\n",
    "        water_mkr=pub.str.contains('fresh',case=False)\n",
    "        df['Category']=np.where(water_mkr,'Fresh Water Maker (RO / VC type)',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        compactor=pub.str.contains('compactor',case=False)\n",
    "        df['Category']=np.where(compactor,'Garbage (Waste) Compactor',df['Category'])\n",
    "\n",
    "        garbage=pub.str.contains('garbage',case=False)\n",
    "        df['Category']=np.where(garbage,'Garbage (Waste) Compactor',df['Category'])\n",
    "\n",
    "        chromatograph=pub.str.contains('chromatograph',case=False)\n",
    "        df['Category']=np.where(chromatograph,'Gas Chromatograph',df['Category'])\n",
    "\n",
    "        gask=pub.str.contains('gask',case=False)\n",
    "        df['Category']=np.where(gask,'Gaskets',df['Category'])\n",
    "        \n",
    "        gask=pub.str.contains('SHAFT SEAL',case=False)\n",
    "        df['Category']=np.where(gask,'Gaskets',df['Category'])\n",
    "        \n",
    "        gask=pub.str.contains('VITON RUBBER',case=False)\n",
    "        df['Category']=np.where(gask,'Gaskets',df['Category'])\n",
    "        \n",
    "        gask=pub.str.contains('PACKING RING',case=False)\n",
    "        df['Category']=np.where(gask,'Gaskets',df['Category'])\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        generator=pub.str.contains('generat',case=False)\n",
    "        df['Category']=np.where(generator,'Generators',df['Category'])\n",
    "\n",
    "        exchanger=pub.str.contains('xchang',case=False)\n",
    "        df['Category']=np.where(exchanger,'Heat Exchangers',df['Category'])\n",
    "\n",
    "        helicopter=pub.str.contains('helicopter',case=False)\n",
    "        df['Category']=np.where(helicopter,'Helicopter Refueling System',df['Category'])\n",
    "\n",
    "        helideck=pub.str.contains('helideck',case=False)\n",
    "        df['Category']=np.where(helideck,'Helideck/Helideck Accessories',df['Category'])\n",
    "\n",
    "        calorify=pub.str.contains('calori',case=False)\n",
    "        df['Category']=np.where(calorify,'Hot Water Calorifier',df['Category'])\n",
    "\n",
    "        air_cond=pub.str.contains('air cond',case=False)\n",
    "        df['Category']=np.where(air_cond,'HVAC',df['Category'])\n",
    "\n",
    "        hydrophor=pub.str.contains('hydroph',case=False)\n",
    "        df['Category']=np.where(hydrophor,'Hydrophore / Pressure Sets.',df['Category'])\n",
    "\n",
    "        pressure_set=pub.str.contains('pressure set',case=False)\n",
    "        df['Category']=np.where(pressure_set,'Hydrophore / Pressure Sets.',df['Category'])\n",
    "\n",
    "        pressure_set=pub.str.contains('pressureset',case=False)\n",
    "        df['Category']=np.where(pressure_set,'Hydrophore / Pressure Sets.',df['Category'])\n",
    "\n",
    "        laser=pub.str.contains('laser',case=False)\n",
    "        df['Category']=np.where(laser,'Laser unit',df['Category'])\n",
    "\n",
    "        life_raft=pub.str.contains('life raft',case=False)\n",
    "        df['Category']=np.where(life_raft,'Life Rafts',df['Category'])\n",
    "\n",
    "        life_raft=pub.str.contains('liferaft',case=False)\n",
    "        df['Category']=np.where(life_raft,'Life Rafts',df['Category'])\n",
    "\n",
    "        life_raft=pub.str.contains('life boat',case=False)\n",
    "        df['Category']=np.where(life_raft,'Life Rafts',df['Category'])\n",
    "\n",
    "        life_raft=pub.str.contains('lifeboat',case=False)\n",
    "        df['Category']=np.where(life_raft,'Life Rafts',df['Category'])\n",
    "\n",
    "        coriolis=pub.str.contains('cori',case=False)\n",
    "        df['Category']=np.where(coriolis,'Mass / Coriolis',df['Category'])\n",
    "\n",
    "        purifier=pub.str.contains('purif',case=False)\n",
    "        df['Category']=np.where(purifier,'Oil Purifiers / Centrifuge',df['Category'])\n",
    "\n",
    "        purifier=pub.str.contains('oil centr',case=False)\n",
    "        df['Category']=np.where(purifier,'Oil Purifiers / Centrifuge',df['Category'])\n",
    "\n",
    "        oily=pub.str.contains('oily',case=False)\n",
    "        df['Category']=np.where(oily,'Oily Water Separator',df['Category'])\n",
    "\n",
    "        oily=pub.str.contains('seperator',case=False)\n",
    "        df['Category']=np.where(oily,'Oily Water Separator',df['Category'])\n",
    "\n",
    "        signal=pub.str.contains('signal',case=False)\n",
    "        df['Category']=np.where(signal,'Signal Converters',df['Category'])\n",
    "\n",
    "        oximeter=pub.str.contains('oximeter',case=False)\n",
    "        df['Category']=np.where(oximeter,'Oximeters',df['Category'])\n",
    "\n",
    "        processor=pub.str.contains('processor',case=False)\n",
    "        df['Category']=np.where(processor,'Processors',df['Category'])\n",
    "\n",
    "        pub_joint=pub.str.contains('pub joint',case=False)\n",
    "        df['Category']=np.where(pub_joint,'Pub Joints',df['Category'])\n",
    "\n",
    "        reverse_osmosis=pub.str.contains('osmo',case=False)\n",
    "        df['Category']=np.where(reverse_osmosis,'Reverse Osmosis',df['Category'])\n",
    "        \n",
    "        reverse_osmosis=pub.str.contains('RO MEMBRANE ELEMENT',case=False)\n",
    "        df['Category']=np.where(reverse_osmosis,'Reverse Osmosis',df['Category'])\n",
    "        \n",
    "        \n",
    "\n",
    "        RTD=pub.str.contains('RTD',case=False)\n",
    "        df['Category']=np.where(RTD,'RTDs',df['Category'])\n",
    "\n",
    "        service=pub.str.contains('service',case=False)\n",
    "        df['Category']=np.where(service,'Services',df['Category'])\n",
    "\n",
    "        service=pub.str.contains('Repair works  MECO vapor compressor',case=False)\n",
    "        df['Category']=np.where(service,'Services',df['Category'])\n",
    "\n",
    "        repair=pub.str.contains('repair',case=False)\n",
    "        df['Category']=np.where(repair,'Services',df['Category'])\n",
    "\n",
    "        overhaul=pub.str.contains('overhaul',case=False)\n",
    "        df['Category']=np.where(overhaul,'Services',df['Category'])\n",
    "\n",
    "        overhaul=pub.str.contains('maint',case=False)\n",
    "        df['Category']=np.where(overhaul,'Services',df['Category'])\n",
    "\n",
    "        overhaul=pub.str.contains('miant',case=False)\n",
    "        df['Category']=np.where(overhaul,'Services',df['Category'])\n",
    "\n",
    "\n",
    "\n",
    "        sewage=pub.str.contains('sew',case=False)\n",
    "        df['Category']=np.where(sewage,'Sewage Treatment Plant',df['Category'])\n",
    "\n",
    "        sewage=pub.str.contains('STP',case=False)\n",
    "        df['Category']=np.where(sewage,'Sewage Treatment Plant',df['Category'])\n",
    "\n",
    "\n",
    "        cable=pub.str.contains('cable',case=False)\n",
    "        df['Category']=np.where(cable,'Cable/Subsea cables and accessories',df['Category'])\n",
    "\n",
    "        sensor=pub.str.contains('sensor',case=False)\n",
    "        df['Category']=np.where(sensor,'Sensors',df['Category'])\n",
    "\n",
    "        tanks=pub.str.contains('tank',case=False)\n",
    "        df['Category']=np.where(tanks,'Tanks',df['Category'])\n",
    "\n",
    "        temperature_sensor=pub.str.contains('temperature sensor',case=False)\n",
    "        df['Category']=np.where(temperature_sensor,'Temperature Sensors',df['Category'])\n",
    "\n",
    "        temperature_sensor=pub.str.contains('tempsensor',case=False)\n",
    "        df['Category']=np.where(temperature_sensor,'Temperature Sensors',df['Category'])\n",
    "\n",
    "        temperature_sensor=pub.str.contains('temp sensor',case=False)\n",
    "        df['Category']=np.where(temperature_sensor,'Temperature Sensors',df['Category'])\n",
    "\n",
    "        temperature_sensor=pub.str.contains('temperaturesensor',case=False)\n",
    "        df['Category']=np.where(temperature_sensor,'Temperature Sensors',df['Category'])\n",
    "\n",
    "        thermo_couple=pub.str.contains('thermocouple',case=False)\n",
    "        df['Category']=np.where(thermo_couple,'Thermocouple',df['Category'])\n",
    "\n",
    "        thermo_couple=pub.str.contains('thermo meter',case=False)\n",
    "        df['Category']=np.where(thermo_couple,'Thermocouple',df['Category'])\n",
    "\n",
    "        thermo_couple=pub.str.contains('thermometer',case=False)\n",
    "        df['Category']=np.where(thermo_couple,'Thermocouple',df['Category'])\n",
    "\n",
    "        thermo_well=pub.str.contains('thermo well',case=False)\n",
    "        df['Category']=np.where(thermo_couple,'Thermowell',df['Category'])\n",
    "\n",
    "        tool=pub.str.contains('tool',case=False)\n",
    "        df['Category']=np.where(tool,'Tools',df['Category'])\n",
    "\n",
    "        transformers=pub.str.contains('transform',case=False)\n",
    "        df['Category']=np.where(transformers,'Transformers',df['Category'])\n",
    "\n",
    "        turbine=pub.str.contains('turbine',case=False)\n",
    "        df['Category']=np.where(turbine,'Turbine Control System',df['Category'])\n",
    "\n",
    "        sterilizer=pub.str.contains('steril',case=False)\n",
    "        df['Category']=np.where(sterilizer,'UV Disinfection System',df['Category'])\n",
    "\n",
    "        vehicles=pub.str.contains('vehicle',case=False)\n",
    "        df['Category']=np.where(vehicles,'Vehicles',df['Category'])\n",
    "\n",
    "        vehicles=pub.str.contains('trailer',case=False)\n",
    "        df['Category']=np.where(vehicles,'Vehicles',df['Category'])\n",
    "\n",
    "        water_distiller=pub.str.contains('distil',case=False)\n",
    "        df['Category']=np.where(water_distiller,'Water distillers',df['Category'])\n",
    "\n",
    "        x_ray=pub.str.contains('xray',case=False)\n",
    "        df['Category']=np.where(x_ray,'X-ray (Parts)',df['Category'])\n",
    "\n",
    "        x_ray=pub.str.contains('x-ray',case=False)\n",
    "        df['Category']=np.where(x_ray,'X-ray (Parts)',df['Category'])\n",
    "\n",
    "        x_ray=pub.str.contains('x_ray',case=False)\n",
    "        df['Category']=np.where(x_ray,'X-ray (Parts)',df['Category'])\n",
    "\n",
    "        x_ray=pub.str.contains('x ray',case=False)\n",
    "        df['Category']=np.where(x_ray,'X-ray (Parts)',df['Category'])\n",
    "        \n",
    "        bearing=pub.str.contains('bearing',case=False)\n",
    "        df['Category']=np.where(bearing,'Bearing',df['Category'])\n",
    "        \n",
    "        oring=pub.str.contains('oring',case=False)\n",
    "        df['Category']=np.where(oring,'O-Ring',df['Category'])\n",
    "        \n",
    "        o_ring=pub.str.contains('o-ring',case=False)\n",
    "        df['Category']=np.where(o_ring,'O-Ring',df['Category'])\n",
    "        \n",
    "        o_ring=pub.str.contains('o ring',case=False)\n",
    "        df['Category']=np.where(o_ring,'O-Ring',df['Category'])\n",
    "\n",
    "        #Newly added\n",
    "\n",
    "        #Ballast Water Treatment System\n",
    "        ballast=pub.str.contains('ballast',case=False)\n",
    "        df['Category']=np.where(ballast,'Ballast Water Treatment System',df['Category'])\n",
    "\n",
    "        #Antifouling System\n",
    "\n",
    "        ballast=pub.str.contains('foul',case=False)\n",
    "        df['Category']=np.where(ballast,'Anti Fouling System',df['Category'])\n",
    "\n",
    "        anti_foul=pub.str.contains('marine growth',case=False)\n",
    "        df['Category']=np.where(anti_foul,'Anti Fouling System',df['Category'])\n",
    "\n",
    "        anti_foul=pub.str.contains('MGPS',case=False)\n",
    "        df['Category']=np.where(anti_foul,'Anti Fouling System',df['Category'])\n",
    "        \n",
    "        batteries=pub.str.contains('ELECTROLYTIC CEL',case=False)\n",
    "        df['Category']=np.where(batteries,'Batteries',df['Category'])\n",
    "\n",
    "        metal_plates=pub.str.contains('plate',case=False)\n",
    "        df['Category']=np.where(metal_plates,'Metal Plates',df['Category'])\n",
    "\n",
    "        compressor=pub.str.contains('compressor',case=False)\n",
    "        df['Category']=np.where(compressor,'Compressor',df['Category'])\n",
    "\n",
    "\n",
    "        pipe=pub.str.contains('SMLS',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "\n",
    "        pipe=pub.str.contains('tubing',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "        \n",
    "        pipe=pub.str.contains('tube',case=False)\n",
    "        df['Category']=np.where(pipe,'Pipes',df['Category'])\n",
    "        \n",
    "        steam_hose=pub.str.contains('steam hose',case=False)\n",
    "        df['Category']=np.where(steam_hose,'Steam Hose',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('COPPER NICKEL ROUND BAR',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "\n",
    "        fitt=pub.str.contains('COPPER NICKEL',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        fitt=pub.str.contains('LOCK NUT',case=False)\n",
    "        df['Category']=np.where(fitt,'Fittings',df['Category'])\n",
    "        \n",
    "        healthcare=pub.str.contains('physio',case=False)\n",
    "        df['Category']=np.where(healthcare,'Fittings',df['Category'])\n",
    "        \n",
    "        healthcare=pub.str.contains('PLAN OBJECTIVE',case=False)\n",
    "        df['Category']=np.where(healthcare,'Healthcare Parts',df['Category'])\n",
    "        \n",
    "        healthcare=pub.str.contains('kineso',case=False)\n",
    "        df['Category']=np.where(healthcare,'Healthcare Parts',df['Category'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        healthcare=pub.str.contains('MASSAGE',case=False)\n",
    "        df['Category']=np.where(healthcare,'Healthcare Parts',df['Category'])\n",
    "        \n",
    "        healthcare=pub.str.contains('ANATOMICAL',case=False)\n",
    "        df['Category']=np.where(healthcare,'Healthcare Parts',df['Category'])\n",
    "        \n",
    "        diff_null=pub.str.contains('Diffuser',case=False)       \n",
    "        df['Category']=np.where(diff_null,\"Diffuser\",df['Category'])\n",
    "        \n",
    "        food_models=pub.str.contains('FOOD MODELS FOR EDUCATION PURPOSE',case=False)       \n",
    "        df['Category']=np.where(food_models,\"Educational Supplies\",df['Category'])\n",
    "        \n",
    "        switch=pub.str.contains('switch',case=False)       \n",
    "        df['Category']=np.where(switch,\"Switch\",df['Category'])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    special_cases()    \n",
    "\n",
    "    #Funnel 6-Oxygen Analyzer\n",
    "    df_oxygen_analyzer=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','oxygen_analyzer')\n",
    "\n",
    "    def oxygen_analyzer():\n",
    "\n",
    "        for oxygen_analyzer in df_oxygen_analyzer['O2 Analyzer Keywords']:\n",
    "\n",
    "            o2_analyzer_keyword=pub.str.contains(oxygen_analyzer,case=False)\n",
    "            df['Category']=np.where(o2_analyzer_keyword,'Oxygen analyzer',df['Category'])\n",
    "    oxygen_analyzer()  \n",
    "\n",
    "    #Funnel 7-Spares\n",
    "    df_spares=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','spares')\n",
    "\n",
    "    def spares():\n",
    "\n",
    "        for spare in df_spares['Spares Keywords']:\n",
    "\n",
    "            spare_keyword=pub.str.contains(spare,case=False)\n",
    "            df['Category']=np.where(spare_keyword,'Spares',df['Category'])\n",
    "    spares()  \n",
    "\n",
    "    df[df['Category']=='Spares'].count()\n",
    "    #df[df['Category']!=\"\"].count()\n",
    "\n",
    "    #Funnel 8-Galley Kitchen Equipment\n",
    "    df_kitchen=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','kitchen_equipment')\n",
    "\n",
    "    def kitchen_equipment():\n",
    "\n",
    "        for kitchen_equipment in df_kitchen['Kitchen Keywords']:\n",
    "\n",
    "            kitchen_keyword=pub.str.contains(kitchen_equipment,case=False)\n",
    "            df['Category']=np.where(kitchen_keyword,'Galley (Kitchen) & Laundry Equipment',df['Category'])\n",
    "\n",
    "    kitchen_equipment()  \n",
    "\n",
    "    #Funnel 9-Testing and Measuring equipment\n",
    "    df_testing=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','testing_equipment')\n",
    "\n",
    "    def testing_equipment():\n",
    "\n",
    "        for testing_equipment in df_testing['Testing Keywords']:\n",
    "\n",
    "            testing_keyword=pub.str.contains(testing_equipment,case=False)\n",
    "            df['Category']=np.where(testing_keyword,'Test And Measuring Instruments',df['Category'])\n",
    "\n",
    "    testing_equipment()  \n",
    "\n",
    "    #Funnel 10-Consumables\n",
    "    df_consumables=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','consumables')\n",
    "\n",
    "    def consumables():\n",
    "\n",
    "        for consumable in df_consumables['Consumables Keywords']:\n",
    "\n",
    "            consumable_keyword=pub.str.contains(consumable,case=False)\n",
    "            df['Category']=np.where(consumable_keyword,'Consumables',df['Category'])\n",
    "\n",
    "    consumables()  \n",
    "\n",
    "    #Funnel 11-Vacuum System\n",
    "\n",
    "    df_vacuum_system=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','vacuum_system')\n",
    "\n",
    "    def vacuum_system():\n",
    "\n",
    "        for system in df_vacuum_system['Vacuum System Keywords']:\n",
    "\n",
    "            system_keyword=pub.str.contains(system,case=False)\n",
    "            df['Category']=np.where(system_keyword,'Vacuum System',df['Category'])\n",
    "\n",
    "    vacuum_system()  \n",
    "\n",
    "     #Funnel 12-Vacuum Toilet\n",
    "\n",
    "    df_vacuum_toilet=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','vacuum_toilet')\n",
    "\n",
    "    def vacuum_toilet():\n",
    "\n",
    "        for toilet in df_vacuum_toilet['Vacuum Toilet Keywords']:\n",
    "\n",
    "            toilet_keyword=pub.str.contains(toilet,case=False)\n",
    "            df['Category']=np.where(toilet_keyword,'Vacuum Toilet',df['Category'])\n",
    "\n",
    "    vacuum_toilet()  \n",
    "\n",
    "    #Funnel 3-Chemicals \n",
    "\n",
    "    def chemicals_keywords():\n",
    "\n",
    "        for chem_keyword in df_chemical['Chemical Keywords']:\n",
    "\n",
    "            chemical_keyword=pub.str.contains(chem_keyword,case=False)\n",
    "            df['Category']=np.where(chemical_keyword,'Chemicals',df['Category'])\n",
    "    chemicals_keywords()  \n",
    "\n",
    "    #df[df['Category']=='Chemicals'].count()\n",
    "\n",
    "    #Funnel 13-Chemical Injection Skid\n",
    "\n",
    "    df_chem_skid=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','chem_skid')\n",
    "\n",
    "    def chem_skid():\n",
    "\n",
    "        for skid in df_chem_skid['Chem Skid Keywords']:\n",
    "\n",
    "            chem_skid_keyword=pub.str.contains(skid,case=False)\n",
    "            df['Category']=np.where(chem_skid_keyword,'Chemical Injection Skid',df['Category'])\n",
    "\n",
    "    chem_skid()  \n",
    "\n",
    "    #Funnel 14-Computer & accessories\n",
    "\n",
    "    df_computer=pd.read_excel('C:/Users/tjoseph/Documents/Python/oms_data.xlsx','computer')\n",
    "\n",
    "    def computer_accessories():\n",
    "\n",
    "        for accessory in df_computer['Computer Accessories Keywords']:\n",
    "\n",
    "            computer_keyword=pub.str.contains(accessory,case=False)\n",
    "            df['Category']=np.where(computer_keyword,'Distributed Control System Parts',df['Category'])\n",
    "\n",
    "    computer_accessories()  \n",
    "    \n",
    "    def kids_eq():\n",
    " \n",
    "        for i in kids_equipments:\n",
    "            puzzle=pub.str.contains(str(i),case=False)\n",
    "            df['Category']=np.where(puzzle,'Educational Supplies',df['Category'])\n",
    "            \n",
    "  \n",
    "\n",
    "    kids_eq()\n",
    "    \n",
    "    \n",
    "    def mechanical_test():\n",
    "        \n",
    "        mechanical_test=pub.str.contains('HYDROPNEUMATIC TEST',case=False)\n",
    "\n",
    "        df['Category']=np.where(mechanical_test,'Mechanical Testing',df['Category'])\n",
    "        \n",
    "    mechanical_test()\n",
    "    \n",
    "    products_categorized=len(df[df['Category']!=\"\"])\n",
    "    \n",
    "    print('Size of DataFrame is {0}'.format(len(df)))\n",
    "    \n",
    "    print('Number of Products Categorized is {0}'.format(products_categorized))\n",
    "    \n",
    "    print('Number of Products NOT Categorized is {0}'.format((len(df)-products_categorized)))\n",
    "    \n",
    "    print('Top 3 categories:',df['Category'].value_counts()[:3])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_all(df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON UAE PURCHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_qualifier(string):\n",
    "    match=re.search(r'(http(s)?://(www.)?)(.*)(\\.\\w*/)',string)\n",
    "    match2=re.sub(r'(http(s)?://(www.)?)','',match.group(0))\n",
    "    match3=re.sub(r'(\\.\\w*\\/)$','',match2)\n",
    "    print('Unqualified Lead:-------------------------',match3.upper())\n",
    "    lead=match3.upper()\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "from googlesearch import search\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "leads_dict={}\n",
    "url_dict={}\n",
    "\n",
    "def google_scrape(url):\n",
    "    thepage = urlopen(url)\n",
    "    soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "    \n",
    "    print('title************************,',soup.title.text)\n",
    "    return soup.title.text\n",
    "\n",
    "\n",
    "def show_suppliers_for(product):\n",
    "    \n",
    "    in_the_uae=str(' UNITED ARAB EMIRATES')\n",
    "    query = str(product)+str(in_the_uae)\n",
    "    print('Searching Google for:',query)\n",
    "    for i,url in enumerate(search(query, stop=10)):\n",
    "        try:\n",
    "            a = google_scrape(url)\n",
    "            print (str(i) + \". \" + a)\n",
    "            print (i,url)\n",
    "            lead_qualifier(url)\n",
    "            leads_dict.setdefault(product,[])\n",
    "            \n",
    "            url_dict.setdefault(product,[])\n",
    "            \n",
    "            url_dict[product].append(url)\n",
    "            \n",
    "            leads_dict[product].append(lead_qualifier(url))\n",
    "        except:\n",
    "            print('Some error at {0}:'.format(url))\n",
    "            lead_qualifier(url)\n",
    "            \n",
    "            leads_dict.setdefault(product,[])\n",
    "            leads_dict[product].append(lead_qualifier(url))\n",
    "    return(leads_dict,url_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "start=time.time()\n",
    "for product in  df_non_UAE_purchase['ITEM_DESCRIPTION']:\n",
    "     show_suppliers_for(product)\n",
    "end=time.time()\n",
    "dt=end-start\n",
    "print('ALTERNATE SUPPLIER QUEST TOOK {0} minutes'.format(dt/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle_in=open('leads_dict.pkl','rb')\n",
    "leads_dict=pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "out_file=open('leads_dict.pkl','wb')\n",
    "leads_dict_pickled=pickle.dump(leads_dict,out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=open('leads_dict.pkl','rb')\n",
    "leads_dict=pickle.load(input_file)\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leads_dict saved as pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leads_list=list(leads_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Mapping NON UAE PURCHASE TO NEW LEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads=pd.DataFrame.from_dict(leads_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.columns=['Lead '+str(x) for x in range(1,(len(df_leads.columns)+1))]\n",
    "df_leads.sort_values(by=['Lead '+str(x) for x in range(1,111)],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting pandas_taking only unique leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.dropna(axis=1,how='all',inplace=True)\n",
    "dummy_df=pd.DataFrame()\n",
    "for i in range(0,len(df_leads)):\n",
    "    \n",
    "     dummy_df=dummy_df.append(df_leads.iloc[i].drop_duplicates())\n",
    "        \n",
    "loop=len(dummy_df)-1\n",
    "#dummy_df.sort_values(by=[x for x in range(1,loop+1)],axis=1,inplace=True)   \n",
    "dummy_df.reset_index(inplace=True)\n",
    "dummy_df.rename(columns={'index':'ITEM_DESCRIPTION'},inplace=True)\n",
    "dummy_df=dummy_df[['ITEM_DESCRIPTION','Lead 1','Lead 2','Lead 3','Lead 4','Lead 5','Lead 6','Lead 7','Lead 8','Lead 9','Lead 10']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame()\n",
    "new_df['ITEM_DESCRIPTION']=\"\"\n",
    "dummy_df_drop=dummy_df.drop(columns=['ITEM_DESCRIPTION'])\n",
    "for i in range(0,512):\n",
    "    item_desc=dummy_df.loc[i]['ITEM_DESCRIPTION']\n",
    "    ttyy=dummy_df_drop.loc[i].sort_values()\n",
    "\n",
    "    ttyy.index=(['Lead '+str(x) for x in range(1,11)])\n",
    "\n",
    "    new_df=new_df.append(ttyy)\n",
    "    new_df['ITEM_DESCRIPTION'][i]=item_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### renaming new_df to df_leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads=new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new leads dataframe length=',len(df_leads))\n",
    "print('Non UAE purchase datframe length=',len(df_non_UAE_purchase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_UAE_purchase['ITEM_DESCRIPTION'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads_merged=pd.merge(df_non_UAE_purchase,df_leads,on=['ITEM_DESCRIPTION'])\n",
    "df_leads_merged.fillna(value=\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_all(df_leads_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-listing bad leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list=pd.read_excel('blacklist.xlsx',sheet_name='blacklist')\n",
    "unique_suppliers=pd.DataFrame(unique_supplier_list) \n",
    "black_list.append(unique_suppliers)\n",
    "\n",
    "\n",
    "def mark_bad_leads():\n",
    "    bad_lead_list=[]\n",
    "    \n",
    "    for i in range(1,11):\n",
    "    \n",
    "        pubb=df_leads_merged['Lead '+str(i)].str.strip()\n",
    "\n",
    "        for  bad_lead in black_list['Blacklist']:\n",
    "            \n",
    "             \n",
    "             bad_lead_list.append(bad_lead)\n",
    "             \n",
    "             bad_lead=pubb.str.contains(str(bad_lead).strip(),case=False)\n",
    "             df_leads_merged['Lead '+str(i)]=np.where(bad_lead,'',df_leads_merged['Lead '+str(i)]) \n",
    "mark_bad_leads()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neww_df=pd.DataFrame()\n",
    "#for i in df_leads_merged.columns[:14]:\n",
    "    #neww_df[str(i)]=\"\"\n",
    "neww_df['ITEM_DESCRIPTION']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neww_df_columns=(list(df_leads_merged.columns[:14])) \n",
    "neww_df_columns.append('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neww_dummy_df_drop=df_leads_merged.drop(columns=neww_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads_merged.loc[df_leads_merged['Lead 1']==\"\",'Lead 1']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 2']==\"\",'Lead 2']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 3']==\"\",'Lead 3']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 4']==\"\",'Lead 4']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 5']==\"\",'Lead 5']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 6']==\"\",'Lead 6']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 7']==\"\",'Lead 7']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 8']==\"\",'Lead 8']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 9']==\"\",'Lead 9']=np.NaN\n",
    "df_leads_merged.loc[df_leads_merged['Lead 10']==\"\",'Lead 10']=np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,(len(df_leads_merged))):\n",
    "    \n",
    "    ttyy=neww_dummy_df_drop.loc[i].sort_values(ascending=False)\n",
    "    \n",
    "    ttyy.index=(['Lead '+str(x) for x in range(1,11)])\n",
    "    item_desc=df_leads_merged.iloc[i]['ITEM_DESCRIPTION']\n",
    "    neww_df=neww_df.append(ttyy)\n",
    "    neww_df['ITEM_DESCRIPTION'][i]=item_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neww_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads_merged.drop(columns=['Lead '+str(c) for c in range(1,11)],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=df_leads_merged.merge(neww_df,on=['ITEM_DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[(final_df['VENDOR_NAME']=='FINDEL EDUCATION LTD') & (final_df['Category']==\"\"),'Category']='Educational Supplies'\n",
    "\n",
    "final_df.loc[(final_df['VENDOR_NAME']=='SPORT-THIEME GmbH') & (final_df['Category']==\"\"),'Category']='Educational Supplies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"\"),'Category']='Healthcare Parts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    \n",
    "\n",
    "    print('Lead '+str(i)+' No values: ',final_df[final_df['Lead '+str(i)]==\"\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df['Category']==\"\"]['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing un-identified Healthcare parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Galley (Kitchen) & Laundry Equipment\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Magnetic\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Fittings\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Test And Measuring Instruments\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Chemicals\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Adhesive\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Distributed Control System Parts\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"Sensors\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Parts') & (final_df['Category']==\"\"),'Category']='Healthcare Parts'\n",
    "\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"Digital\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"Domestic Furniture & Fixtures\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"Ultrasound\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"Consumables\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='HEALTHCARE.Equipment') & (final_df['Category']==\"Test And Measuring Instruments\"),'Category']='Healthcare Parts'\n",
    "final_df.loc[(final_df['CATEGORY']=='TEDESCHI.Furniture') & (final_df['Category']==\"\"),'Category']='Healthcare Parts'\n",
    "\n",
    "final_df.loc[(final_df['CATEGORY']=='EVAC.Parts') & (final_df['Category']==\"\"),'Category']='Marine Spares'\n",
    "final_df.loc[(final_df['CATEGORY']=='MECO.Parts') & (final_df['Category']==\"\"),'Category']='Marine Spares'\n",
    "\n",
    "\n",
    "final_df.loc[(final_df['CATEGORY']=='PRODUCTION CHEMICALS.Chemicals') & (final_df['Category']==\"\"),'Category']='Chemicals'\n",
    "final_df.loc[(final_df['CATEGORY']=='PRODUCTION CHEMICALS.Equipment') & (final_df['Category']==\"\"),'Category']='Chemicals'\n",
    "\n",
    "\n",
    "final_df.loc[(final_df['CATEGORY']=='YOKOGAWA.Parts') & (final_df['Category']==\"\"),'Category']='Spares'\n",
    "\n",
    "final_df.loc[(final_df['CATEGORY']=='NATCO.Parts') & (final_df['Category']==\"\"),'Category']='Spares'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[(final_df['VENDOR_NAME']=='HEADHUNTER INC') & (final_df['Category']!=\"STP UNIT/PARTS\"),'Category']='STP UNIT/PARTS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[(final_df['PRODUCT MANAGER'] ==\"\") & (final_df['CATEGORY']=='NATCO.Parts'),'PRODUCT MANAGER']='Shahid Jamil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('df_leads.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purchase from abroad PM-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for  i in final_df['PRODUCT MANAGER'].unique():\n",
    " \n",
    "    jk=final_df[final_df['PRODUCT MANAGER']==i][['TOTALINAED','ITEM_DESCRIPTION','Category']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(i,':',round(jk['TOTALINAED'].sum()/1000000,2),'million AED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Best alternates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    \n",
    "    lead='Lead '+str(i)\n",
    "\n",
    "    print('Best Alternates :',list(filter(None,(list(final_df[lead].value_counts().index[:5])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting unique leads amongst all (from Lead 1 to Lead 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_list=[]\n",
    "for i in range(1,11):\n",
    "    \n",
    "    \n",
    "    lead='Lead '+str(i)\n",
    "    \n",
    "    lead=set((final_df[lead]))\n",
    "    \n",
    "    \n",
    "    lead=list(lead)\n",
    "    \n",
    "    final_list=final_list+lead\n",
    "    \n",
    "unique_leads_set=set(final_list) \n",
    "unique_leads_list=list(filter(None,unique_leads_set))\n",
    "len(unique_leads_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end=time.time()\n",
    "dt=(end-start)/60\n",
    "minutes=int(str(dt).split('.')[0])\n",
    "seconds=int(round((float('.'+str(dt).split('.')[1])*60),0))\n",
    "print('Time taken for execution = {0} minutes {1} seconds'.format(minutes,seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting company description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting company description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_info(x):\n",
    "    \n",
    "    print(time.ctime())\n",
    "    \n",
    "    lead_title_url={}\n",
    "    global soup\n",
    "    \n",
    "    for i,url in enumerate(search((str(unique_leads_list[x])),start=0,stop=1,num=1)):\n",
    "\n",
    "\n",
    "        lead=unique_leads_list[x]\n",
    "        \n",
    "        \n",
    "\n",
    "        print(url)\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "        try:\n",
    "            req = urllib.request.Request(url, data=None,headers={'User-Agent': 'Chrome'})\n",
    "            req = urllib.request.urlopen(req, timeout=300)\n",
    "            page=req\n",
    "\n",
    "               \n",
    "        \n",
    "        \n",
    "        except:\n",
    "            \n",
    "            print('error')\n",
    "            \n",
    "            #page=urlopen(url,timeout=152)\n",
    "            #req = urllib.request.Request(url, data=None,headers={'User-Agent': 'Chrome'})\n",
    "            \n",
    "            #time.sleep(30)\n",
    "                       \n",
    "            #req = urllib.request.urlopen(req, timeout=200)\n",
    "            #page=req\n",
    "            exit()\n",
    " \n",
    "        try:       \n",
    "              \n",
    "            soup=BeautifulSoup(page,'html.parser') \n",
    "            \n",
    "        except:\n",
    "            print('SOUP ERROR')\n",
    "            \n",
    "        title=soup.title\n",
    "        title=re.sub(r'^<title>','',str(title))\n",
    "        title=re.sub(r'</title>','',str(title))\n",
    "        \n",
    "        lead_title_url.setdefault(lead,[])\n",
    "        lead_title_url[lead].append(title)\n",
    "        lead_title_url[lead].append(url)\n",
    "\n",
    "        print('-------------LEAD--------------',lead,'*************TITLE**************',title)\n",
    "        \n",
    "    return [soup,url,lead_title_url,lead,title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get contact string pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_content_list(x):\n",
    "    \n",
    "    \n",
    "    soup=get_company_info(x)[0]\n",
    "    content_list_elements=[]\n",
    "    for link in soup.find_all('a'):\n",
    "        content_list_elements.append(link.get_text()) \n",
    "    content_list = soup.find_all('a')\n",
    "\n",
    "\n",
    "    print('Length of content list = ',len(content_list))\n",
    "\n",
    "    #print(\"CONTENT LIST ELEMENTS:\")\n",
    "\n",
    "    for i in range(0,(len(content_list)-1)):\n",
    "\n",
    "        content_list_elements.append(content_list[i].getText().split('\\n')[0])\n",
    "\n",
    "    return content_list_elements\n",
    "             \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format of contact page in the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contact_tab_title(x):\n",
    "    \n",
    "    text=None\n",
    "    \n",
    "    content_list_elements=make_content_list(x)\n",
    "    \n",
    "    for i,contact in enumerate(content_list_elements):\n",
    "\n",
    "        contact_match=re.search(r'(\\s*)?contact(\\s*)?(us)?(\\s*)?',contact,flags=re.IGNORECASE)\n",
    "        if contact_match!=None:\n",
    "            print('Contact Page in website : ',contact_match.group(0))\n",
    "            text=contact\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            text=None\n",
    "            \n",
    "    return text\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_leads_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_leads_list.sort(reverse=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "output_file=open('unique_leads_list.pkl','wb')\n",
    "unique_leads_pickle=pickle.dump(unique_leads_list,output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_file=open('unique_leads_list.pkl','rb')\n",
    "unique_leads_list=pickle.load(input_file)\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull telephone num from Contact us page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return [soup,url,lead_title_url,lead,title]\n",
    "\n",
    "def find_telephone_num():\n",
    "    import time\n",
    "    telephone_dictionary={}\n",
    "    print('Compiling starts  at:',time.ctime())\n",
    "\n",
    "    for x in range(0,len(unique_leads_list)):\n",
    "\n",
    "        print('Processing Lead : ',x)\n",
    "\n",
    "        text=find_contact_tab_title(x)\n",
    "        content_list_elements=make_content_list(x)\n",
    "        soup=soup=get_company_info(x)[0]\n",
    "\n",
    "        url=get_company_info(x)[1]\n",
    "        lead=get_company_info(x)[3]\n",
    "        company_title=get_company_info(x)[4]\n",
    "\n",
    "\n",
    "\n",
    "        telephone_dictionary.setdefault(lead,[])\n",
    "\n",
    "        telephone_dictionary[lead].append(company_title)\n",
    "\n",
    "        telephone_dictionary[lead].append(url)\n",
    "\n",
    "\n",
    "\n",
    "    # search specific keyword (text) \n",
    "\n",
    "        if text in content_list_elements:\n",
    "\n",
    "            contact_page_pattern=soup.find_all('a',text=text)\n",
    "\n",
    "\n",
    "            url_match=re.search(r'(http(s)?://(www.)?)(.*)(\\.\\w*/)',url)\n",
    "            url_cleaned=url_match.group(0)\n",
    "\n",
    "            #print('Cleaned URL: ',str(url_cleaned))\n",
    "\n",
    "\n",
    "            if len(contact_page_pattern)!=0:\n",
    "\n",
    "                contact_page=re.sub(r'(^.*href=\")','',str(contact_page_pattern[0]))\n",
    "                contact_page=re.sub(r'\".*','',str(contact_page))\n",
    "\n",
    "\n",
    "\n",
    "                contact_page_url=str(contact_page)\n",
    "\n",
    "                print('Contact page URL: ',contact_page_url)\n",
    "\n",
    "                if '<a>' in contact_page_url:\n",
    "\n",
    "\n",
    "\n",
    "                    contact_page=re.sub(r'(^<a>)','',str(contact_page_url))\n",
    "                    contact_page=re.sub(r'(</a>)','',str(contact_page))\n",
    "\n",
    "                    contact_page_url=str(contact_page)\n",
    "\n",
    "\n",
    "\n",
    "                if 'http' in contact_page_url:\n",
    "\n",
    "                    url_to_be_searched=str(contact_page_url)\n",
    "\n",
    "                    print('Contact number could be found in: ',url_to_be_searched)\n",
    "\n",
    "                else :\n",
    "\n",
    "                    url_to_be_searched=str(url_cleaned)+str(contact_page_url)\n",
    "\n",
    "\n",
    "                    print('Contact number could be found in: ',url_to_be_searched)\n",
    "\n",
    "                try:\n",
    "                    req = urllib.request.Request(url_to_be_searched, data=None, headers={'User-Agent': 'Chrome'})\n",
    "                    req = urllib.request.urlopen(req, timeout=300)\n",
    "                    contact_page=req\n",
    "\n",
    "\n",
    "                except:\n",
    "\n",
    "                    print('CONTACT PAGE  ERROR')\n",
    "                    #req = urllib.request.Request(url_to_be_searched, data=None,headers={'User-Agent': 'Chrome'})\n",
    "                    #req = urllib.request.urlopen(req, timeout=300)\n",
    "                    #contact_page=req\n",
    "\n",
    "\n",
    "                try:\n",
    "\n",
    "\n",
    "                    contact_soup=BeautifulSoup(contact_page,'html.parser')\n",
    "\n",
    "                except:\n",
    "\n",
    "                    print('CONTACT SOUP ERROR')\n",
    "\n",
    "\n",
    "                digits_dict={}\n",
    "\n",
    "                regex_patterns=[]\n",
    "\n",
    "\n",
    "                #uae telephone pattern 1\n",
    "                tele_pattern1=re.compile(r'(^\\+971)(\\s)\\d{0,10}(\\s)?\\d{0,10}\\d{0,10}')\n",
    "                regex_patterns.append(tele_pattern1)\n",
    "\n",
    "                #uae telephone pattern 2\n",
    "                tele_pattern2=re.compile(r'\\+971([^a-zA-Z\\,.]){1,20}\\d')\n",
    "                regex_patterns.append(tele_pattern2)\n",
    "\n",
    "                tele_pattern3=re.compile(r'\\+\\d\\s\\d{3}\\s\\-\\d{3}\\-\\d{4}')\n",
    "                regex_patterns.append(tele_pattern3)\n",
    "\n",
    "                # numbers with hypen(-)\n",
    "                tele_pattern4=re.compile(r'(\\+)\\d{1,3}(\\s)?(\\-)\\d{1,3}\\-\\d{1,5}\\-\\d{1,5}')\n",
    "                regex_patterns.append(tele_pattern4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #landline format.numbers like 04 254 99 72 \n",
    "\n",
    "                tele_pattern5=re.compile(r'EDAYANIKKATTU')\n",
    "                regex_patterns.append(tele_pattern5)\n",
    "\n",
    "\n",
    "                tele_pattern6=re.compile(r'EDAYANIKKATTU')\n",
    "                regex_patterns.append(tele_pattern6)\n",
    "\n",
    "\n",
    "                #number of format : ' 00971-6-533 1830'\n",
    "\n",
    "                tele_pattern7=re.compile(r'EDAYANIKKATTU')\n",
    "                regex_patterns.append(tele_pattern7)\n",
    "\n",
    "                # numbers like '+971 (6) 5432538'\n",
    "                tele_pattern8=re.compile(r'(\\s+)?(\\+)?971(\\s)?([^a-zA-Z\\@\\/\\:].){1,20}')\n",
    "                regex_patterns.append(tele_pattern8)\n",
    "\n",
    "\n",
    "\n",
    "                #patterns like  800-972-6461\n",
    "                tele_pattern9=re.compile(r'(\\s)?(800)\\-\\d{1,5}\\-\\d*')\n",
    "                regex_patterns.append(tele_pattern9)\n",
    "\n",
    "                tele_pattern10=re.compile(r'(^(\\s+)?(02|04|06)([^a-zA-Z\\@\\/\\:].){1,10}\\d?)')\n",
    "                regex_patterns.append(tele_pattern10)\n",
    "\n",
    "\n",
    "\n",
    "                tele_pattern11=re.compile(r'(\\s)+?(02|04|05|06|07|08)([^a-zA-Z\\@\\/\\:].){1,20}')\n",
    "                regex_patterns.append(tele_pattern11)\n",
    "\n",
    "                #teles like +41 22 994 47 00\n",
    "\n",
    "                tele_pattern12=re.compile(r'\\+(\\s)?(\\d{1,3})([^a-zA-Z].){1,20}')\n",
    "\n",
    "                regex_patterns.append(tele_pattern12)\n",
    "\n",
    "\n",
    "                tele_pattern13=re.compile(r'\\d{4}\\s\\d{3}\\s\\d{4}')\n",
    "                regex_patterns.append(tele_pattern13)\n",
    "\n",
    "\n",
    "\n",
    "                for i,tele_pattern in enumerate(regex_patterns): \n",
    "\n",
    "                    match=re.search(tele_pattern,str(contact_soup))\n",
    "\n",
    "                    if match!=None:\n",
    "\n",
    "                        global telephone\n",
    "                        telephone=match.group(0)\n",
    "\n",
    "                        digits=re.sub(r'[<>,()\"]',' ',telephone)\n",
    "                        digits=re.sub(r'[a-zA-Z]',' ',digits)\n",
    "\n",
    "                        digits_dict[telephone]=digits\n",
    "\n",
    "                        #print('Digits dict::',digits_dict)\n",
    "\n",
    "\n",
    "                        print('Telephone number extracted is {0}'.format(telephone))\n",
    "\n",
    "                        print('TELEPHONE NUMBER PATTERN FOUND FROM  TELE_PATTERN'+ str(i+1))\n",
    "\n",
    "\n",
    "                        # telephone=digits with highest number count\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        print('No pattern found from tele_pattern '+ str(i+1))\n",
    "\n",
    "\n",
    "                #print('final digts dict-----------',digits_dict)\n",
    "\n",
    "                values=[x for x in list(digits_dict.values())]\n",
    "                values.sort(key=lambda x:len(x),reverse=True)\n",
    "\n",
    "                if len(values)!=0:\n",
    "\n",
    "                    final_telephone_num=values[0]\n",
    "\n",
    "                    print('FINAL Telephone number extracted is {0}'.format(final_telephone_num))\n",
    "                    print('No of digits in telephone is:',len(final_telephone_num))\n",
    "\n",
    "                    telephone_dictionary[lead].append(final_telephone_num)\n",
    "\n",
    "                    out_file=open('telephone_dictionary.pkl','wb')\n",
    "                    telephone_dictionary_file=pickle.dump(telephone_dictionary,out_file)\n",
    "                    out_file.close()\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    telephone_dictionary[lead].append('No pattern matched')\n",
    "\n",
    "                    out_file=open('telephone_dictionary.pkl','wb')\n",
    "                    telephone_dictionary_file=pickle.dump(telephone_dictionary,out_file)\n",
    "                    out_file.close()\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(contact_page_pattern,'*****Length of contact page pattern:******',len(contact_page_pattern))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('NO CONTACT PAGE FOUND ')\n",
    "            telephone_dictionary[lead].append('No contact page found')\n",
    "\n",
    "            out_file=open('telephone_dictionary.pkl','wb')\n",
    "            telephone_dictionary_file=pickle.dump(telephone_dictionary,out_file)\n",
    "            out_file.close()\n",
    "\n",
    "\n",
    "\n",
    "    print('Compiling ended  at:',time.ctime()) \n",
    "\n",
    "\n",
    "    import pickle\n",
    "    out_file=open('telephone_dictionary_final.pkl','wb')\n",
    "    telephone_dictionary_file=pickle.dump(telephone_dictionary,out_file)\n",
    "    out_file.close()\n",
    "    leads_dataframe=pd.DataFrame.from_dict(telephone_dictionary,orient='index',columns=['Description','Website','Telephone'])\\\n",
    "    .reset_index().rename(columns={'index':'Alternate_Supplier'})\n",
    "    leads_dataframe.to_excel('leads_tele_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os,re\n",
    "import pandas as pd\n",
    "os.chdir('C://Users//tjoseph//Desktop//ICV docs')\n",
    "in_file=open('telephone_dictionary.pkl','rb')\n",
    "pickled=pickle.load(in_file)\n",
    "in_file.close()\n",
    "\n",
    " \n",
    "\n",
    "leads_dataframe=pd.DataFrame.from_dict(pickled,orient='index',columns=['Description','Website','Telephone'])\\\n",
    ".reset_index().rename(columns={'index':'Alternate_Supplier'})\n",
    "df_tele=leads_dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_tele.drop(index=245,inplace=True)\n",
    "\n",
    " \n",
    "\n",
    "df_tele['Telephone']=df_tele['Telephone'].apply(lambda x: str(x).strip('/'))\n",
    "\n",
    "df_tele['Telephone']=df_tele['Telephone'].apply(lambda x:re.sub(r'[^0-9\\+\\-\\/]',' ',str(x)))\n",
    "\n",
    "df_tele['Telephone']=df_tele['Telephone'].apply(lambda x:(str(x).strip()))\n",
    "\n",
    "df_tele['Telephone']=df_tele['Telephone'].apply(lambda x:re.sub(r'\\/$','',str(x)))\n",
    "\n",
    "df_tele['Telephone']=df_tele['Telephone'].apply(lambda x:re.sub(r'\\/$','',str(x).strip()))\n",
    "\n",
    " \n",
    "\n",
    "df_tele['Description']=df_tele['Description'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\|\\- _ ]',' ',str(x)))\n",
    "\n",
    "df_tele['Digits']=df_tele['Telephone'].apply(lambda x: re.sub(r'[^0-9]',' ',str(x)))\n",
    "\n",
    "df_tele['Digits_count']=df_tele['Digits'].apply(lambda x: len([c for c in x if c.isdigit()]))\n",
    "\n",
    " \n",
    "\n",
    "df_tele['Digits']=df_tele['Digits'].apply(lambda x: ''.join([c for c in x if c.isdigit()] ))\n",
    "\n",
    "df_tele_masked=df_tele.mask(df_tele['Digits_count']<=8)\n",
    "\n",
    " \n",
    "df_tele_masked.dropna(inplace=True)\n",
    "\n",
    " \n",
    "\n",
    "df_tele_un_masked=df_tele.mask(df_tele.Digits_count>=8,inplace=False)\n",
    "df_tele_un_masked.dropna(inplace=True)\n",
    "\n",
    "df_tele.sort_values(by='Digits_count',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele_masked['Telephone_work']=df_tele_masked['Telephone'].apply(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tele_masked.loc[df_tele_masked['Telephone_work'].str.startswith('02'),'Telephone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele.rename(columns={'Alternate_Supplier':'Lead 1'},inplace=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele.drop(columns=['Digits_count','Digits'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_try=final_df[['Category','Lead 1','Lead 2',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging=merge_try.merge(df_tele,how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele_masked.sort_values(by='Digits_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele_masked.iloc[96:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele_merged=pd.merge(final_df,df_tele,on=('Lead 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tele.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(final_df,df_tele,on='Lead 1',indicator=True,how='left').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,11):\n",
    "\n",
    "    final_df=pd.merge(final_df,df_tele,on=('Lead '+str(x)),how='left')\n",
    "\n",
    "    final_df.rename(columns={'Website':('Website'+str(x)),'Telephone':('Telephone'+str(x)),'Description':('Description'+str(x))},inplace=True)\n",
    "    df_tele.rename(columns={('Lead '+str(x)):('Lead '+str(x+1))},inplace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['Lead 1','Website1','Description1','Lead 2','Website2','Lead 3','Website3','Telephone3']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('Master_Dataframe2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
